// avcodec_sample.0.5.0.c

#include <libavcodec/avcodec.h>
//RSA#include <libavformat/avformat.h>
#include <libswscale/swscale.h>

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>

#include "destreamer.h"
#include "config.h"

static void SaveFrame(AVFrame *pFrame, int width, int height, int iFrame);

int main (int argc, const char * argv[])
{
    int             i;
    AVCodecContext  *pCodecCtx;
    AVCodec         *pCodec;
    AVFrame         *pFrame;
    AVFrame         *pFrameRGB;
    int             frameFinished;
	int 	numBytes;
	void * buffer;

    // Open video file
open_264( argv[1] );
if( NULL == ds.buffer )
		{
		printf("couldn't open file\n");
        return -1; // Couldn't open file
		}

	avcodec_register_all();

    // Find the decoder for the video stream
    pCodec=avcodec_find_decoder(CODEC_ID_H264);
    if(pCodec==NULL)
		{
		printf("No codec\n");
        return -1; // Codec not found
		}

    // Open codec
	pCodecCtx = avcodec_alloc_context();
	pCodecCtx->pix_fmt=0;
	pCodecCtx->width=WIDTH;
	pCodecCtx->height=HEIGHT;
    if(avcodec_open(pCodecCtx, pCodec)<0)
		{
		printf("couldn't open codec\n");
        return -1; // Could not open codec
		}

    // Hack to correct wrong frame rates that seem to be generated by some codecs
    if(pCodecCtx->time_base.num>1000 && pCodecCtx->time_base.den==1)
		pCodecCtx->time_base.den=1000;

    // Allocate video frame
    pFrame=avcodec_alloc_frame();

    // Allocate an AVFrame structure
    pFrameRGB=avcodec_alloc_frame();
    if(pFrameRGB==NULL)
		{
		printf("Frame alloc failed\n");
		return -1;
		}

	printf("width=%i height=%i\n",pCodecCtx->width,pCodecCtx->height);

    // Determine required buffer size and allocate buffer
    numBytes=avpicture_get_size(PIX_FMT_RGB24, pCodecCtx->width,pCodecCtx->height);

	buffer=malloc(numBytes);

    // Assign appropriate parts of buffer to image planes in pFrameRGB
    avpicture_fill((AVPicture *)pFrameRGB, buffer, PIX_FMT_RGB24,pCodecCtx->width, pCodecCtx->height);

    // Read frames and save first five frames to disk
    i=0;
	while( get_next_block() )
    {
        // Is this a packet from the video stream?...of course!
        {
			frameFinished = 0;
            // Decode video frame
            avcodec_decode_video(pCodecCtx, pFrame, &frameFinished, &ds.buffer[ds.last_pos], ds.cur_pos-ds.last_pos);

            // Did we get a video frame?
			printf("ff=%i\n",frameFinished);
            if(frameFinished)
            {
				static struct SwsContext *img_convert_ctx;

				// Convert the image into YUV format that SDL uses
				if(img_convert_ctx == NULL) {
					int w = pCodecCtx->width;
					int h = pCodecCtx->height;

					img_convert_ctx = sws_getContext(w, h, pCodecCtx->pix_fmt, w, h, PIX_FMT_RGB24, SWS_BICUBIC,NULL, NULL, NULL);
					if(img_convert_ctx == NULL) {
						fprintf(stderr, "Cannot initialize the conversion context!\n");
						exit(1);
					}
				}
				sws_scale(img_convert_ctx, pFrame->data, pFrame->linesize, 0, pCodecCtx->height, pFrameRGB->data, pFrameRGB->linesize);
                // Save the frame to disk
                if(i++<=5)
                    SaveFrame(pFrameRGB, pCodecCtx->width, pCodecCtx->height, i);
            }
        }

    }

    // Free the RGB image
    free(buffer);
    av_free(pFrameRGB);

    // Free the YUV frame
    av_free(pFrame);

    // Close the codec
    avcodec_close(pCodecCtx);

	close_264();

    return 0;
}

static void SaveFrame(AVFrame *pFrame, int width, int height, int iFrame)
{
    FILE *pFile;
    char szFilename[32];
    int  y;

    // Open file
    sprintf(szFilename, "frame%d.ppm", iFrame);
    pFile=fopen(szFilename, "wb");
    if(pFile==NULL)
        return;

    // Write header
    fprintf(pFile, "P6\n%d %d\n255\n", width, height);

    // Write pixel data
    for(y=0; y<height; y++)
        fwrite(pFrame->data[0]+y*pFrame->linesize[0], 1, width*3, pFile);

    // Close file
    fclose(pFile);
}
