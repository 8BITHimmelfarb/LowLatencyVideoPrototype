extern "C"
	{
	#include <libavcodec/avcodec.h>
	#include <libswscale/swscale.h>
	}
#include <stddef.h>
#include <stdint.h>
#include <stdio.h>

#include "config.h"

#include "data_source_ocv_avcodec.h"

#include "opencv/highgui.h"

data_source_ocv_avcodec::data_source_ocv_avcodec(const char * name)
{
	int 	numBytes;
m_name = strdup( name );
cvNamedWindow( m_name, CV_WINDOW_AUTOSIZE);

avcodec_register_all();

// Find the decoder for the video stream
pCodec=avcodec_find_decoder(CODEC_ID_H264);
if(pCodec==NULL)
	{
	printf("No codec\n");
	}

// Open codec
pCodecCtx = avcodec_alloc_context();
pCodecCtx->pix_fmt=PIX_FMT_YUV420P;
pCodecCtx->width=WIDTH;
pCodecCtx->height=HEIGHT;
if(avcodec_open(pCodecCtx, pCodec)<0)
	{
	printf("couldn't open codec\n");
	}

// Hack to correct wrong frame rates that seem to be generated by some codecs
if(pCodecCtx->time_base.num>1000 && pCodecCtx->time_base.den==1)
	pCodecCtx->time_base.den=1000;

// Allocate video frame
pFrame=avcodec_alloc_frame();

// Allocate an AVFrame structure
pFrameRGB=avcodec_alloc_frame();
if(pFrameRGB==NULL)
	{
	printf("Frame alloc failed\n");
	}

// Determine required buffer size and allocate buffer
numBytes=avpicture_get_size(PIX_FMT_RGB24, pCodecCtx->width,pCodecCtx->height);

buffer=malloc(numBytes);

// Assign appropriate parts of buffer to image planes in pFrameRGB
avpicture_fill((AVPicture *)pFrameRGB, (uint8_t*)buffer, PIX_FMT_RGB24,pCodecCtx->width, pCodecCtx->height);
}

data_source_ocv_avcodec::~data_source_ocv_avcodec()
{
cvDestroyWindow( m_name );
free( (void*)m_name );

// Free the RGB image
free(buffer);
av_free(pFrameRGB);

// Close the codec
// Free the YUV frame
av_free(pFrame);
avcodec_close(pCodecCtx);
}

void data_source_ocv_avcodec::write( const uint8_t * data, size_t bytes )
{
int             frameFinished=0;
// Decode video frame
avcodec_decode_video(pCodecCtx, pFrame, &frameFinished, data, bytes);

// Did we get a video frame?
if(frameFinished)
	{
	IplImage * output_image = cvCreateImageHeader(cvSize(pCodecCtx->width,pCodecCtx->height),IPL_DEPTH_8U,3);
	static struct SwsContext *img_convert_ctx;


	// Convert the image into YUV format that SDL uses
	if(img_convert_ctx == NULL)
		{
		int w = pCodecCtx->width;
		int h = pCodecCtx->height;

		img_convert_ctx = sws_getContext(w, h, pCodecCtx->pix_fmt, w, h, PIX_FMT_RGB24, SWS_BICUBIC,NULL, NULL, NULL);
		if(img_convert_ctx == NULL)
			{
			fprintf(stderr, "Cannot initialize the conversion context!\n");
			exit(1);
			}
		}
	sws_scale(img_convert_ctx, pFrame->data, pFrame->linesize, 0, pCodecCtx->height, pFrameRGB->data, pFrameRGB->linesize);

	// Blit
	output_image->imageData = (char*)pFrameRGB->data[0];
	cvShowImage(m_name,output_image);
	cvWaitKey(10);
	output_image->imageData = NULL;
	cvReleaseImageHeader( &output_image );
	}
}
